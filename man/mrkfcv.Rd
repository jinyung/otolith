\name{mrkfcv}
\alias{mrkfcv}
\title{Multiple-run k-fold cross-validation}
\usage{
mrkfcv(X, Y, method = "lda", k = 5, threshold = NULL, ncomp = NULL,
  run = 100, suppress = FALSE)
}
\arguments{
  \item{run}{number of run to be used in multiple runs of
  k-fold cross-validation}

  \item{suppress}{suppress the running status in R console}

  \item{X}{matrix/ dataframe of predictors, e.g. EFA
  coefficients/ PC scores selected using
  \code{\link{selectdim}}}

  \item{Y}{vector giving the class, e.g. \code{sp} value
  from \code{\link{routine1}} object}

  \item{method}{method \code{"\link{lda}"} for linear
  discriminant analysis, \code{"\link{tree}"} for
  classification tree, \code{"\link{plsda}"} for partial
  least square-linear discriminant analysis}

  \item{k}{fold number of cross-validation}

  \item{threshold}{optional. A numeric value between 0-1 to
  set the threshold of posterior probility. Any class
  prediction with posterior probility lower than this value
  will be \code{NA}-ed and not reported.}

  \item{ncomp}{argument passed to \code{\link{plsda}}.Used
  only when \code{method="plsda"}.}
}
\value{
\item{accuracy}{cross-validated accuracy for the tested
classifier, resulted from the average of \code{k x ru}n
numbers of accuracy generated by the function}
\item{accu.sd}{standard deviation for the accuracy,
calculated from the \code{k x run} number of results}
\item{total}{mean total successful prediction in percent,
give \code{NA} if \code{threshold} is not given}
\item{total.sd}{sd of total successful prediction in
percent, give \code{NA} if \code{threshold} is not given}
\item{misclass}{vector of \code{run x k} number of
misclassification rate} \item{total.pred}{raw prediction
success for \code{run x k} number of submodels, give
\code{NULL} if \code{threshold} is not given}
}
\description{
run multiple runs of k-fold cross validation, see referece.
"Use all data" variant is implemented here.
}
\references{
Bouckaert, R.R., 2003. Choosing between two learning
algorithms based on calibrated tests. In: Fawcett, T.,
Mishra, N. (Eds.), Proceedings of the Twentieth
International Conference (ICML 2003) on Machine Learning.
August 21-24, 2003, AAAI Press, Washington.

Beleites, C., Baumgartner, R., Bowman, C., Somorjai, R.,
Steiner, G., Salzer, R., & Sowa, M. G. (2005). Variance
reduction in estimating classification error using sparse
datasets.  Chemometrics and Intelligent Laboratory Systems,
79(1), 91-100.
}
\seealso{
Similar: \code{\link{mrkfcv2}}

Which this function wraps: \code{\link{kfcv}}

Function that wraps this function: \code{\link{pccv}},
\code{\link{harcv}}, \code{\link{threcv}}
}

