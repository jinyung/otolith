\name{mrkfcv / mrkfcv2}
\alias{mrkfcv}
\alias{mrkfcv2}
\title{Multiple-run k-fold cross-validation}
\usage{
mrkfcv(X, Y, method = c("lda", "tree", "plsda"), k = 5, run = 100,
  threshold, ncomp, suppress = c(FALSE, TRUE, "text"))
mrkfcv2(X, Y, method = c("lda", "tree", "plsda"), k = 5, run = 100,
  threshold, ncomp, suppress = FALSE)
}
\arguments{
  \item{X}{matrix/ dataframe of predictors, e.g. EFA
    coefficients/ PC scores selected using
    \code{\link{selectdim}}}

  \item{Y}{vector giving the class, e.g. value obtained from 
    \code{\link{getclass}} or \code{sp} value
    from \code{\link{routine1}} object}

  \item{method}{method \code{"\link{lda}"} for linear
    discriminant analysis, \code{"\link{tree}"} for
    classification tree, \code{"\link{plsda}"} for partial
    least square-linear discriminant analysis}

  \item{k}{fold number of cross-validation}

  \item{run}{number of run to be used in multiple runs of
    k-fold cross-validation}

  \item{threshold}{optional. A numeric value between 0-1 to
    set the threshold of posterior probility. Any class
    prediction with posterior probility lower than this value
    will be \code{NA}-ed and not reported. See \code{\link{threcv}}}
    
  \item{suppress}{suppress the running status in R console
  when \code{TRUE}. [for \code{mrkfcv}] the option \code{"text"} is used for
  \code{\link{pccv}/\link{harcv}} wrappers}
  }
  
\value{
  \item{accuracy}{cross-validated accuracy for the tested
    classifier, resulted from the average of \code{k x run}
    numbers of accuracy generated by the function}
  \item{accu.sd}{standard deviation for the accuracy,
    calculated from the \code{k x run} number of results}
  \item{total}{mean
    total successful prediction in percent, not returned if
    \code{threshold} value is not given} 
  \item{total.sd}{sd of total
    successful prediction in percent, not returned if
    \code{threshold} value is not given}
  \item{misclass}{[\code{mrkfcv} only] vector of \code{run x k} number of
    misclassification rate} 
  \item{ind.prediction}{[\code{mrkfcv} only] vector of precentage of correctly 
  predicted specimens}
  \item{stat.sum}{[\code{mrkfcv2} only] cross-validated by-class precision, recall
    and specificity} 
  \item{conmat}{[\code{mrkfcv2} only] confusion matrix shown in
    proportion, average across all confusion matrices of
    \code{k x run} number of submodels. Proportion = number
    correctly or incorrectly predicted divided by the total
    number of that class in training set.} 
}
\description{
  run multiple runs of k-fold cross validation, see referece.
  "Use all data" variant is implemented here.
}
\details{
  \code{mrkfcv} is a wrapper for \code{kfcv} while
  \code{mrkfcv2} is a wrapper for \code{kfcv2}, both of which iterate them for 
  a number of times specified by \code{run} argument. 
  
  For \code{mrkfcv}, the \code{ind.prediction} value is the precentage calculated
  from \code{run} number of results. This calculation is useful when user wish to 
  find out problematic specimen(s) during building classification model.
  
  For \code{mrkfcv2}, the calculated by-class statistics (\code{stat.sum}) are
  average of all values of number of \code{k x run} of
  submodels (\code{NA} values are excluded).
}
\references{
  Bouckaert, R.R., (2003). Choosing between two learning
  algorithms based on calibrated tests. In: Fawcett, T.,
  Mishra, N. (Eds.), \emph{Proceedings of the Twentieth
  International Conference (ICML 2003) on Machine Learning}.
  August 21-24, 2003, AAAI Press, Washington.
  
  Beleites, C., Baumgartner, R., Bowman, C., Somorjai, R.,
  Steiner, G., Salzer, R., & Sowa, M. G. (2005). Variance
  reduction in estimating classification error using sparse
  datasets.  \emph{Chemometrics and Intelligent Laboratory
  Systems}, 79(1), 91-100.
}
\seealso{
Which this function wraps: \code{\link{kfcv}}, \code{\link{kfcv2}}
}
