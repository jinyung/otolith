\name{mrkfcv2}
\alias{mrkfcv2}
\title{Multiple-run k-fold cross-validation (version-2)}
\usage{
mrkfcv2(X, Y, method = "lda", k = 5, run = 100, suppress = FALSE,
  threshold = NULL, ncomp = NULL)
}
\arguments{
  \item{X}{matrix/ dataframe of predictors, e.g. EFA
  coefficients/ PC scores selected using
  \code{\link{selectdim}}}

  \item{Y}{vector giving the class, e.g. \code{sp} value
  from \code{\link{routine1}} object}

  \item{method}{method \code{"\link{lda}"} for linear
  discriminant analysis, \code{"\link{tree}"} for
  classification tree, \code{"\link{plsda}"} for partial
  least square-linear discriminant analysis}

  \item{k}{fold number of cross-validation}

  \item{run}{number of run to be used in multiple runs of
  k-fold cross-validation}

  \item{suppress}{suppress the running status in R console}

  \item{threshold}{optional. A numeric value between 0-1 to
  set the threshold of posterior probility. Any class
  prediction with posterior probility lower than this value
  will be \code{NA}-ed and not reported.}

  \item{ncomp}{argument passed to \code{\link{plsda}}.Used
  only when \code{method="plsda"}.}
}
\value{
\item{accuracy}{cross-validated accuracy for the tested
classifier, resulted from the average of \code{k x ru}n
numbers of accuracy generated by the function}
\item{accu.sd}{standard deviation for the accuracy,
calculated from the \code{k x run} number of results}
\item{stat.sum}{cross-validated by-class precision, recall
and specificity} \item{conmat}{confusion matrix shown in
proportion, average across all confusion matrices of
\code{k x run} number of submodels. Proportion = number
correctly or incorrectly predicted divided by the total
number of that class in training set.} \item{total}{mean
total successful prediction in percent, give \code{NA} if
\code{threshold} is not given} \item{total.sd}{sd of total
successful prediction in percent, give \code{NA} if
\code{threshold} is not given}
}
\description{
modified version of \code{\link{mrkfcv}}, comes with
calculation of recall, precision, and specificity.
}
\details{
The calculated by-class statistics (\code{stat.sum}) are
average of all values of number of \code{k x run} of
submodels (\code{NA} values are excluded).
}
\references{
Bouckaert, R.R., 2003. Choosing between two learning
algorithms based on calibrated tests. In: Fawcett, T.,
Mishra, N. (Eds.), Proceedings of the Twentieth
International Conference (ICML 2003) on Machine Learning.
August 21-24, 2003, AAAI Press, Washington.
}
\seealso{
Similar: \code{\link{mrkfcv}}

Which this function wraps: \code{\link{kfcv2}}
}

